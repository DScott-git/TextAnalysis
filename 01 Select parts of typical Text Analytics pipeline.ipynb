{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics - Discovery (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#These only need to be done once...\n",
    "#nltk.download('punkt')                      \n",
    "#nltk.download('averaged_perceptron_tagger') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.4\n"
     ]
    }
   ],
   "source": [
    "print((nltk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize into sentences and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:     5 \n",
      "    Words:   136\n"
     ]
    }
   ],
   "source": [
    "#one big text... \n",
    "\n",
    "text = u\"\"\"\n",
    "On this day, we gather because we have chosen hope over fear, unity of purpose over conflict and discord. \n",
    "On this day, we come to proclaim an end to the petty grievances and false promises, \n",
    "the recriminations and worn-out dogmas that for far too long have strangled our politics. We remain a young \n",
    "nation. But in the words of Scripture, the time has come to set aside childish things. The time has \n",
    "come to reaffirm our enduring spirit; to choose our better history; to carry forward that precious gift, \n",
    "that noble idea passed on from generation to generation: the God-given promise that all are equal, all \n",
    "are free, and all deserve a chance to pursue their full measure of happiness.\n",
    "\"\"\"\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentnc = nltk.sent_tokenize(text)\n",
    "\n",
    "# Word Tokenization\n",
    "wrds = [nltk.word_tokenize(s) for s in sentnc]\n",
    "\n",
    "print(\"Sentences: {:>5} \\n    Words: {:>5}\".format(len(sentnc), sum(len(x)for x in wrds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We remain a young \\nnation.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: dont forget to ask... Should we clean these before we use them?\n",
    "sentnc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'remain', 'a', 'young', 'nation', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['IN', 'DT', 'NN', ',', 'PRP', 'VBP', 'IN', 'PRP', 'VBP', 'VBN', 'NN', 'IN', 'NN', ',', 'NN', 'IN', 'NN', 'IN', 'NN', 'CC', 'NN', '.'], ['IN', 'DT', 'NN', ',', 'PRP', 'VBP', 'TO', 'VB', 'DT', 'NN', 'TO', 'DT', 'JJ', 'NNS', 'CC', 'JJ', 'NNS', ',', 'DT', 'NNS', 'CC', 'NN', 'NN', 'IN', 'IN', 'RB', 'RB', 'RB', 'VBP', 'VBN', 'PRP$', 'NNS', '.'], ['PRP', 'VBP', 'DT', 'JJ', 'NN', '.'], ['CC', 'IN', 'DT', 'NNS', 'IN', 'NNP', ',', 'DT', 'NN', 'VBZ', 'VBN', 'TO', 'VB', 'RB', 'JJ', 'NNS', '.'], ['DT', 'NN', 'VBZ', 'VBN', 'TO', 'VB', 'PRP$', 'VBG', 'NN', ':', 'TO', 'VB', 'PRP$', 'JJR', 'NN', ':', 'TO', 'VB', 'RB', 'IN', 'JJ', 'NN', ',', 'IN', 'JJ', 'NN', 'VBN', 'IN', 'IN', 'NN', 'TO', 'NN', ':', 'DT', 'NNP', 'NN', 'IN', 'DT', 'VBP', 'JJ', ',', 'DT', 'VBP', 'JJ', ',', 'CC', 'DT', 'VBP', 'DT', 'NN', 'TO', 'VB', 'PRP$', 'JJ', 'NN', 'IN', 'NN', '.']]\n"
     ]
    }
   ],
   "source": [
    "#This will create a list of (token, POS tag) for each token in the doc\n",
    "\n",
    "tagged_wt = [nltk.pos_tag(w)for w in wrds]     #<<< using the word list\n",
    "\n",
    "## [[('On', 'IN'), ('this', 'DT'), ('day', 'NN'), (',', ','), ('we', 'PRP') ...\n",
    "\n",
    "patternPOS= []    \n",
    "\n",
    "#add all the parts of speech into that list: patternPOS\n",
    "for tag in tagged_wt:\n",
    "    patternPOS.append([v for k,v in tag])\n",
    "\n",
    "\n",
    "print(patternPOS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Nouns or noun like words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'hope', 'fear', 'unity', 'purpose', 'conflict', 'discord']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = []       #what will I do with this empty list?\n",
    "\n",
    "for tag in tagged_wt:\n",
    "    nouns.append([k for k,v in tag if v in ['NN','NNS','NNP','NNPS']])\n",
    "    \n",
    "nouns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gather', 'have', 'chosen'], ['come', 'proclaim', 'have', 'strangled']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = [] \n",
    "\n",
    "for tag in tagged_wt:\n",
    "    verbs.append([k for k,v in tag if v in ['VB','VBD','VBG','VBN','VBP','VBZ']])\n",
    "\n",
    "verbs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 nouns and 22 verbs in the text.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} nouns and {} verbs in the text.\".format(sum(len(l) for l in nouns), sum(len(l) for l in verbs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "##### More feature extraction and explorations\n",
    "\n",
    "spacy.__en_core_web_lg__\n",
    "\n",
    "English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities. (https://spacy.io/models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These need to be downloaded before we can use them. \n",
    "#!python -m spacy download en_pytt_xlnetbasecased_lg  \n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "#python -m spacy download en  #<<-- get the English language models\n",
    "import spacy\n",
    "\n",
    "print((spacy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On this day, we gather because we have chosen hope over fear, unity of purpose over conflict and discord. \n",
      "On this day, we come to proclaim an end to the petty grievances and false promises, \n",
      "the recriminations and worn-out dogmas that for far too long have strangled our politics. We remain a young \n",
      "nation. But in the words of Scripture, the time has come to set aside childish things. The time has \n",
      "come to reaffirm our enduring spirit; to choose our better history; to carry forward that precious gift, \n",
      "that noble idea passed on from generation to generation: the God-given promise that all are equal, all \n",
      "are free, and all deserve a chance to pursue their full measure of happiness.\n",
      "\n",
      "\n",
      " SPACE \n",
      "On ADP prep\n",
      "this DET det\n",
      "day NOUN pobj\n",
      ", PUNCT punct\n",
      "we PRON nsubj\n",
      "gather VERB ROOT\n",
      "because SCONJ mark\n",
      "we PRON nsubj\n",
      "have AUX aux\n",
      "chosen VERB advcl\n",
      "hope NOUN dobj\n",
      "over ADP prep\n",
      "fear NOUN pobj\n",
      ", PUNCT punct\n",
      "unity NOUN conj\n",
      "of ADP prep\n",
      "purpose NOUN pobj\n",
      "over ADP prep\n",
      "conflict NOUN pobj\n",
      "and CCONJ cc\n",
      "discord NOUN conj\n",
      ". PUNCT punct\n",
      "\n",
      " SPACE \n",
      "On ADP prep\n",
      "this DET det\n",
      "day NOUN pobj\n",
      ", PUNCT punct\n",
      "we PRON nsubj\n",
      "come VERB ROOT\n",
      "to PART aux\n",
      "proclaim VERB advcl\n",
      "an DET det\n",
      "end NOUN dobj\n",
      "to ADP prep\n",
      "the DET det\n",
      "petty ADJ amod\n",
      "grievances NOUN pobj\n",
      "and CCONJ cc\n",
      "false ADJ amod\n",
      "promises NOUN conj\n",
      ", PUNCT punct\n",
      "\n",
      " SPACE \n",
      "the DET det\n",
      "recriminations NOUN nsubjpass\n",
      "and CCONJ cc\n",
      "worn VERB amod\n",
      "- PUNCT punct\n",
      "out ADP prt\n",
      "dogmas NOUN conj\n",
      "that PRON mark\n",
      "for ADP prep\n",
      "far ADV advmod\n",
      "too ADV advmod\n",
      "long ADV advmod\n",
      "have AUX aux\n",
      "strangled VERB acl\n",
      "our PRON poss\n",
      "politics NOUN dobj\n",
      ". PUNCT punct\n",
      "We PRON nsubj\n",
      "remain VERB ROOT\n",
      "a DET det\n",
      "young ADJ amod\n",
      "\n",
      " SPACE \n",
      "nation NOUN attr\n",
      ". PUNCT punct\n",
      "But CCONJ cc\n",
      "in ADP prep\n",
      "the DET det\n",
      "words NOUN pobj\n",
      "of ADP prep\n",
      "Scripture NOUN pobj\n",
      ", PUNCT punct\n",
      "the DET det\n",
      "time NOUN nsubj\n",
      "has AUX aux\n",
      "come VERB ROOT\n",
      "to PART aux\n",
      "set VERB advcl\n",
      "aside ADV prt\n",
      "childish ADJ amod\n",
      "things NOUN dobj\n",
      ". PUNCT punct\n",
      "The DET det\n",
      "time NOUN nsubj\n",
      "has AUX ROOT\n",
      "\n",
      " SPACE \n",
      "come VERB ccomp\n",
      "to PART aux\n",
      "reaffirm VERB advcl\n",
      "our PRON poss\n",
      "enduring VERB amod\n",
      "spirit NOUN dobj\n",
      "; PUNCT punct\n",
      "to PART aux\n",
      "choose VERB acl\n",
      "our PRON poss\n",
      "better ADJ amod\n",
      "history NOUN dobj\n",
      "; PUNCT punct\n",
      "to PART aux\n",
      "carry VERB acl\n",
      "forward ADV advmod\n",
      "that SCONJ det\n",
      "precious ADJ amod\n",
      "gift NOUN dobj\n",
      ", PUNCT punct\n",
      "\n",
      " SPACE \n",
      "that DET mark\n",
      "noble ADJ amod\n",
      "idea NOUN nsubj\n",
      "passed VERB relcl\n",
      "on ADP prt\n",
      "from ADP prep\n",
      "generation NOUN pobj\n",
      "to ADP prep\n",
      "generation NOUN pobj\n",
      ": PUNCT punct\n",
      "the DET det\n",
      "God PROPN npadvmod\n",
      "- PUNCT punct\n",
      "given VERB amod\n",
      "promise NOUN dobj\n",
      "that SCONJ mark\n",
      "all DET nsubj\n",
      "are AUX relcl\n",
      "equal ADJ acomp\n",
      ", PUNCT punct\n",
      "all DET nsubj\n",
      "\n",
      " SPACE \n",
      "are AUX advcl\n",
      "free ADJ acomp\n",
      ", PUNCT punct\n",
      "and CCONJ cc\n",
      "all DET nsubj\n",
      "deserve VERB conj\n",
      "a DET det\n",
      "chance NOUN dobj\n",
      "to PART aux\n",
      "pursue VERB acl\n",
      "their PRON poss\n",
      "full ADJ amod\n",
      "measure NOUN dobj\n",
      "of ADP prep\n",
      "happiness NOUN pobj\n",
      ". PUNCT punct\n",
      "\n",
      " SPACE \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#the 'nlp' is the model\n",
    "nlp = spacy.load('en_core_web_lg')  #the _lg (large) has the word embeddings\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(doc.text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PROPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adposition'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ADP\") #am I a linguist? What is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  https://glossary.sil.org/term/adposition  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun          Count\n",
      "----------  -------\n",
      "day               2\n",
      "promise           2\n",
      "time              2\n",
      "generation        2\n",
      "hope              1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "\n",
    "#token.lemma_ is the base form of the token, with no inflectional suffixes.\n",
    "\n",
    "noun_counter = Counter(token.lemma_ for token in doc if token.pos_ == 'NOUN')\n",
    "\n",
    "print(tabulate(noun_counter.most_common(5), headers=['Noun', 'Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('day', 2), ('promise', 2), ('time', 2), ('generation', 2), ('hope', 1), ('fear', 1), ('unity', 1), ('purpose', 1), ('conflict', 1), ('discord', 1), ('end', 1), ('grievance', 1), ('recrimination', 1), ('dogma', 1), ('politic', 1), ('nation', 1), ('word', 1), ('scripture', 1), ('thing', 1), ('spirit', 1), ('history', 1), ('gift', 1), ('idea', 1), ('chance', 1), ('measure', 1), ('happiness', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(noun_counter.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity    Entity Type\n",
      "--------  -------------\n",
      "Srinivas  PERSON\n",
      "India     GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"My name is Srinivas and I live in India.\")\n",
    "\n",
    "entity_types = ((ent.text, ent.label_) for ent in doc.ents)\n",
    "\n",
    "print(tabulate(entity_types, headers=['Entity', 'Entity Type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK POS Tagger meanings \n",
    "- __CC__ coordinating conjunction\n",
    "\n",
    "- __CD__ cardinal digit\n",
    "\n",
    "- __DT__ determiner\n",
    "\n",
    "- __EX__ existential there (like: “there is” … think of it like “there exists”)\n",
    "\n",
    "- __FW__ foreign word\n",
    "\n",
    "- __IN__ preposition/subordinating conjunction\n",
    "\n",
    "- __JJ__ adjective ‘big’\n",
    "\n",
    "- __JJR__ adjective, comparative ‘bigger’\n",
    "\n",
    "- __JJS__ adjective, superlative ‘biggest’\n",
    "\n",
    "- __LS__ list marker 1)\n",
    "\n",
    "- __MD__ modal could, will\n",
    "\n",
    "- __NN__ noun, singular ‘desk’\n",
    "\n",
    "- __NNS__ noun plural ‘desks’\n",
    "\n",
    "- __NNP__ proper noun, singular ‘Harrison’\n",
    "\n",
    "- __NNPS__ proper noun, plural ‘Americans’\n",
    "\n",
    "- __PDT__ predeterminer ‘all the kids’\n",
    "\n",
    "- __POS__ possessive ending parent‘s\n",
    "\n",
    "- __PRP__ personal pronoun I, he, she\n",
    "\n",
    "- __PRP$__ possessive pronoun my, his, hers\n",
    "\n",
    "- __RB__ adverb very, silently,\n",
    "\n",
    "- __RBR__ adverb, comparative better\n",
    "\n",
    "- __RBS__ adverb, superlative best\n",
    "\n",
    "- __RP__ particle give up\n",
    "\n",
    "- __TO__ to go ‘to‘ the store.\n",
    "\n",
    "- __UH__ interjection errrrrrrrm\n",
    "\n",
    "- __VB__ verb, base form take\n",
    "\n",
    "- __VBD__ verb, past tense took\n",
    "\n",
    "- __VBG__ verb, gerund/present participle taking\n",
    "\n",
    "- __VBN__ verb, past participle taken\n",
    "\n",
    "- __VBP__ verb, sing. present, non-3d take\n",
    "\n",
    "- __VBZ__ verb, 3rd person sing. present takes\n",
    "\n",
    "- __WDT__ wh-determiner which\n",
    "\n",
    "- __WP__ wh-pronoun who, what\n",
    "\n",
    "- __WP$__ possessive wh-pronoun whose\n",
    "\n",
    "- __WRB__ wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__References:__\n",
    "\n",
    "https://www.nltk.org/book/\n",
    "\n",
    "http://www.nltk.org/howto/\n",
    "\n",
    "https://www.geeksforgeeks.org/part-speech-tagging-stop-words-using-nltk-python/  \n",
    "\n",
    "https://spacy.io/api\n",
    "\n",
    "Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.\n",
    "\n",
    "Tukey, John (1977), Exploratory Data Analysis, Addison-Wesley.\n",
    "\n",
    "Brown, D. W. (2016) Corpus of Presidential Speeches. Retrieved from http://www.thegrammarlab.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
